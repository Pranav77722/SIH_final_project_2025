<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Assistant Demo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            background-color: #f7f7f7;
            color: #333;
        }

        .container {
            text-align: center;
            padding: 20px;
            background: #fff;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
            width: 400px;
        }

        h1 {
            font-size: 24px;
            margin-bottom: 20px;
        }

        .button-group {
            margin: 20px 0;
        }

        button {
            padding: 10px 20px;
            margin: 10px;
            font-size: 16px;
            cursor: pointer;
            border: none;
            border-radius: 5px;
            background-color: #4CAF50;
            color: white;
        }

        button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }

        #status {
            margin-top: 20px;
            font-size: 18px;
        }

        #transcript, #assistant {
            margin-top: 15px;
            font-size: 18px;
            padding: 10px;
            background-color: #f1f1f1;
            border-radius: 5px;
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        #assistant {
            background-color: #e0f7fa;
        }

        .input-group {
            margin-top: 20px;
        }

        #manual {
            width: 80%;
            padding: 10px;
            font-size: 16px;
            border-radius: 5px;
            border: 1px solid #ccc;
        }

        select {
            padding: 10px;
            margin-top: 10px;
        }
    </style>
</head>
<body>

<div class="container">
    <h1>Voice Assistant</h1>
    <div class="button-group">
        <button id="startBtn">Start Listening</button>
        <button id="stopBtn" disabled>Stop Listening</button>
        <button id="stopRespondingBtn" disabled>Stop Responding</button>
    </div>

    <div class="input-group">
        <textarea id="manual" placeholder="Type something for the assistant..." rows="4"></textarea>
        <div>
            <button id="sendManual">Send Manual</button>
            <button id="clearBtn">Clear</button>
        </div>
    </div>

    <div>
        <select id="lang">
            <option value="en-IN">English (India)</option>
            <option value="en-US">English (US)</option>
            <option value="en-GB">English (UK)</option>
            <option value="hi-IN">Hindi (India)</option>
        </select>
        <button id="askTextBtn">Ask Text</button>
    </div>

    <div id="status">Idle</div>
    <div id="transcript">—</div>
    <div id="assistant">—</div>
</div>

<script>
    const START_BTN = document.getElementById('startBtn');
    const STOP_BTN = document.getElementById('stopBtn');
    const STOP_RESPONDING_BTN = document.getElementById('stopRespondingBtn');
    const LANG_SEL = document.getElementById('lang');
    const TRANSCRIPT = document.getElementById('transcript');
    const ASSISTANT = document.getElementById('assistant');
    const STATUS = document.getElementById('status');
    const MANUAL = document.getElementById('manual');
    const SEND_MANUAL = document.getElementById('sendManual');
    const CLEAR_BTN = document.getElementById('clearBtn');
    const ASK_TEXT_BTN = document.getElementById('askTextBtn');

    const GEMINI_API_KEY = "AIzaSyCdInN8hYL28X3tWt1ZxRjsBgwCAEJ5vBg"; 
    const GEMINI_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent";
    // const MODEL_NAME = "gemini-1.5-flash"; // Not needed in URL approach directly but implied

    let recognition = null;
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
        STATUS.textContent = "SpeechRecognition not supported. Use Chrome/Edge.";
        START_BTN.disabled = true;
    } else {
        recognition = new SpeechRecognition();
        recognition.interimResults = false;
        recognition.maxAlternatives = 1;

        recognition.onstart = () => { STATUS.textContent = "Listening..."; };
        recognition.onend = () => { STATUS.textContent = "Idle"; START_BTN.disabled = false; STOP_BTN.disabled = true; };
        recognition.onerror = (e) => { STATUS.textContent = "Error: " + e.error; START_BTN.disabled = false; STOP_BTN.disabled = true; };

        recognition.onresult = async (ev) => {
            const text = ev.results[0][0].transcript;
            TRANSCRIPT.textContent = text;
            STATUS.textContent = "Got transcript — sending to server...";
            await askGemini(text, LANG_SEL.value);
        };
    }

    // Start/Stop listeners
    START_BTN.addEventListener('click', () => {
        if (!recognition) return;
        recognition.lang = LANG_SEL.value || 'en-IN';
        START_BTN.disabled = true;
        STOP_BTN.disabled = false;
        try {
            recognition.start();
        } catch (err) {
            console.error(err);
            START_BTN.disabled = false;
            STOP_BTN.disabled = true;
        }
    });

    STOP_BTN.addEventListener('click', () => {
        if (recognition) {
            recognition.stop();
            STOP_BTN.disabled = true;
            START_BTN.disabled = false;
        }
    });

    STOP_RESPONDING_BTN.addEventListener('click', () => {
        speechSynthesis.cancel();
        STATUS.textContent = 'Stopped responding';
        STOP_RESPONDING_BTN.disabled = true;
        START_BTN.disabled = false;
    });

    SEND_MANUAL.addEventListener('click', async () => {
        const q = MANUAL.value.trim();
        if (!q) return alert('Type a question');
        TRANSCRIPT.textContent = q;
        await askGemini(q, LANG_SEL.value);
    });

    CLEAR_BTN.addEventListener('click', () => {
        TRANSCRIPT.textContent = '—';
        ASSISTANT.textContent = '—';
        MANUAL.value = '';
    });

    ASK_TEXT_BTN.addEventListener('click', () => {
        MANUAL.focus();
    });

    async function askGemini(userText, lang = 'en-IN') {
        STATUS.textContent = 'Contacting Gemini...';
        ASSISTANT.textContent = 'Thinking...';

        const payload = {
            contents: [{
                parts: [{ text: userText }]
            }],
            systemInstruction: {
                parts: [{ text: 'SAKSHAM is a Digital Beneficiary Identification & Management System for the PM-AJAY GIA scheme. It includes: Citizen Android App (Aadhaar login, auto-profile, document upload using CameraX, vernacular + voice guidance, real-time tracking). Officer Portal (document-level approval, discrepancy resolution, geotagged field verification, dashboards). State Admin Portal (scheme configuration, fund tracking, analytics). SAKSHAM User Constraints: Low literacy, vernacular preference, poor connectivity, 42% document rejection due to bad uploads, 58% smartphone availability (Ghulewadi). Citizens without phones apply through CSC / Panchayat helpdesk / enumerators with SMS/IVR updates.  SAKSHAM Core Goals: Reduce processing time (47→7 days), reduce leakage (<5%), lower inclusion/exclusion errors (<8%), improve transparency (38%→100%). SAKSHAM Accessibility (GIGW 3.0): Must follow WCAG 2.1 AA: screen reader support, high-contrast mode, 200% text scaling, alt-text, keyboard navigation, simple-language mode, voice guidance, step-by-step flows, cognitive disability support (icons+text, consistent layout, clear errors). GIGW 3 Cybersecurity (GIGW 3.0): Must follow ISO 27001, CERT-IN controls, OWASP Top 10/ASVS, role-based access, encrypted data (TLS 1.3 + AES-256), audit logs, VAPT, Safe-to-Host certification. GIGW 3Architecture: Kotlin app, React + Node portals, Firebase backend (prototype), mock Aadhaar/DigiLocker/PFMS APIs—production must use real integrations with proper consent & security. SAKSHAMRules for AI:Always ensure compliance with GIGW 3.0, WCAG 2.1 AA, CERT-IN security.Always offer non-smartphone alternatives (CSC, enumerator, web portal).Keep answers simple, structured, and actionable.Cite SAKSHAM report or GIGW where relevant.' }]
            },
            generationConfig: {
                temperature: 0.2,
                maxOutputTokens: 300
            }
        };

        try {
            const res = await fetch(`${GEMINI_URL}?key=${GEMINI_API_KEY}`, {
                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify(payload)
            });

            if (!res.ok) {
                const body = await res.text();
                ASSISTANT.textContent = `Gemini error: ${res.status} ${res.statusText}\n${body}`;
                STATUS.textContent = 'Error';
                console.error('Gemini error', res.status, body);
                return;
            }

            const j = await res.json();
            let reply = j?.candidates?.[0]?.content?.parts?.[0]?.text?.trim() || '[no reply]';

            // Remove '*' from the reply
            reply = reply.replace(/\*/g, '');

            ASSISTANT.textContent = reply;
            STATUS.textContent = 'Answered — speaking';

            // Speak the reply using Web Speech Synthesis
            speakText(reply, lang);

        } catch (err) {
            ASSISTANT.textContent = 'Network or CORS error: ' + err.message;
            STATUS.textContent = 'Network error';
            console.error(err);
        }
    }

    function speakText(text, lang = 'en-IN') {
        if (!('speechSynthesis' in window)) {
            console.warn('SpeechSynthesis not supported');
            return;
        }

        const utter = new SpeechSynthesisUtterance(text);
        utter.lang = lang;

        const voices = speechSynthesis.getVoices() || [];
        let chosen = null;
        if (voices.length) {
            chosen = voices.find(v => v.lang && v.lang.toLowerCase().startsWith(lang.toLowerCase()));
            if (!chosen) chosen = voices.find(v => v.lang && v.lang.toLowerCase().startsWith('en'));
        }
        if (chosen) utter.voice = chosen;

        utter.onerror = (e) => { console.error('TTS error', e); STATUS.textContent = 'TTS error'; };
        utter.onend = () => { 
            STATUS.textContent = 'Idle'; 
            STOP_RESPONDING_BTN.disabled = true; 
        };

        speechSynthesis.cancel();
        speechSynthesis.speak(utter);

        STOP_RESPONDING_BTN.disabled = false;
    }
</script>

</body>
</html>
